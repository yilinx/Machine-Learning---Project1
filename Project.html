<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta name="generator" content="pandoc" />



<title></title>

<script src="Project_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="Project_files/bootstrap-2.3.2/css/bootstrap.min.css" rel="stylesheet" />
<link href="Project_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="Project_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="Project_files/highlight/default.css"
      type="text/css" />
<script src="Project_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>


<link rel="stylesheet" href="custom.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">




<div id="weight-lifting-excercises" class="section level1">
<h1>Weight lifting excercises</h1>
<p></BR> </BR></p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The aim of this piece of work is to explore using machine learning to determine how “correctly” one perfroms their physical workout. This is extremely important especially in atheletes and elderlies who are more susceptible to injuries from physical workouts.</p>
<p>In this study, large amount of data were collected from 6 participants. These data were from accelerometers on the belt, forearm, arm, and dumbell. The participant were asked to perform barbell lifts correctly and incorrectly in 5 different ways.</p>
<p>In this work, the sensor data are being divided into 3 datasets. The training set, the testing set and the validation set.</p>
<p>The strategy adopted to perform the machine learning is as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Conduct various types of machine learning on the training set to construct the prediction model</p></li>
<li><p>Perform out of sample error estimation by applying the prediction model on the testing dataset</p></li>
<li><p>Select the most accurate prediction model</p></li>
<li><p>Apply the selected model on the validation set</p></li>
</ol>
<pre class="r"><code># download and read the training and testing files
library(caret)
library(gbm)
#setInternet2(TRUE)
#trainfileloc &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
#validatefileloc &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;

#download.file(trainfileloc, &quot;training.csv&quot;)
#download.file(validatefileloc, &quot;validate.csv&quot;)

train &lt;- read.csv(&quot;training.csv&quot;,na.strings=c(&quot;NA&quot;,&quot;&quot;), stringsAsFactors=F)
validate &lt;- read.csv(&quot;validate.csv&quot;)

set.seed(1234)
inTrain &lt;- createDataPartition(y=train$classe, p=0.7, list=F)

test &lt;- train[-inTrain,]
train &lt;- train[inTrain,]</code></pre>
</div>
<div id="data-processing" class="section level2">
<h2>Data processing</h2>
<p>Before we proceed to perform the machine learning on the data, the raw data must be processed to extract variables that are relevant for predictions and to addresss missing and/or NA values.</p>
<p>The approach taken is as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Remove features having almost zero variance: This is to remove variables with very few unique values</p></li>
<li><p>Remove features with many NAs: Analysis into the training dataset showed that most of the columns either have more than 90% of NAs or less than 10% of NAs. Hence columns having more than 90% values being NAs are removed from the analysis</p></li>
<li><p>Keep data with complete cases</p></li>
</ol>
<pre class="r"><code>#remove near zero value
nzv &lt;- nearZeroVar(train)
train.process &lt;- train[,-nzv]

#remove columns with large number of NA
na.test &lt;- function(x) {
        sum(is.na(x))
        }
try &lt;- apply(train.process,2,na.test)
try &lt;- try/nrow(train.process)*100    #percentage of NAs in each column
try.select &lt;- data.frame(try[try&lt;0.9])  #keep columns having less than 90% of NA values, ie more         than 90% of enerties are NA, we discard the column

train.process &lt;- subset(train.process, select=c(rownames(try.select)))

#remove some column names such as &quot;X&quot;, &quot;user_name&quot;, &quot;raw_timestamp_part_1&quot;, 
#&quot;raw_timestamp_part_2&quot;, &quot;cvtd_timestamp&quot;, &quot;num_window&quot; 
train.process &lt;- train.process[,-(1:6)]
train.proC &lt;- train.process[complete.cases(train.process),]   #keep only completecase enteries</code></pre>
</div>
<div id="machine-learning" class="section level2">
<h2>Machine Learning</h2>
<p>To ensure the reproducibility of the results, 4567 is set as the seed for the calculations.</p>
<p>The models experimented include</p>
<ol style="list-style-type: decimal">
<li><p>RandomForest</p></li>
<li><p>Stochastic Gradient Boosting</p></li>
<li><p>Linear Discriminant Analysis</p></li>
<li><p>RandomForest with principle component analysis (PCA) implemented</p></li>
</ol>
<p>The reason for experimenting a random forest model with PCA implemented is to study the accuracy difference of random forest with and without PCA. As random forest is a very computation intensive learning algorithm, if the accuracy is not affected by the presence of PCA, it would be worth considering trading off a little accuracy for faster computation time.</p>
<p>To obtain better acccuracy, a 10-fold cross validation was used with the command trainControl(method=“cv”, number=10)</p>
<p>In the PCA preprocessing step, a threshold was set to collect 99% of the variance in the data.</p>
<pre class="r"><code>set.seed(4567)

#train control setting
fitControl &lt;- trainControl(method=&quot;cv&quot;, number=10)
fitControl.pca &lt;- trainControl(method=&quot;cv&quot;, number=10, preProcOptions = list(thresh = 0.99, ICAcomp = 3, k = 5))

#various types of models

#randomForest model
lag.rf &lt;- system.time(modFit.rf &lt;- train(factor(classe)~., method=&quot;rf&quot;, trControl = fitControl, data=train.proC))  

#gbm model
lag.gbm &lt;- system.time(modFit.gbm &lt;- train(factor(classe)~., method=&quot;gbm&quot;, trControl=fitControl, data=train.proC, verbose=F))

#lda model
lag.lda &lt;- system.time(modFit.lda &lt;- train(factor(classe)~., method=&quot;lda&quot;, trControl=fitControl, data=train.proC))

#randomForest with pca model
lag.rfpca &lt;- system.time(modFit.rfpca &lt;- train(factor(classe)~., method=&quot;rf&quot;, trControl = fitControl.pca, preProcess = &quot;pca&quot;, data=train.proC))</code></pre>
</div>
<div id="accuracy-results" class="section level2">
<h2>Accuracy Results</h2>
<pre class="r"><code>library(caret)
calacc &lt;- function(modelObj){
  acc &lt;- confusionMatrix(test$classe,predict(modelObj,test))
  acc &lt;- acc$overall[1]
  return(acc)
}

modList &lt;- list(modFit.rf,modFit.gbm,modFit.lda,modFit.rfpca)
calsummary &lt;- data.frame(lapply(modList,calacc))
names(calsummary) &lt;- c(&quot;RandomForest&quot;,&quot;GBM&quot;,&quot;LDA&quot;,&quot;RandomForest-PCA&quot;)
calsummary &lt;- rbind(calsummary,c(lag.rf[3],lag.gbm[3],lag.lda[3],lag.rfpca[3]))
row.names(calsummary) &lt;- c(&quot;Accuracy&quot;,&quot;Elapsed Time&quot;)</code></pre>
<p></BR></p>
<!-- html table generated in R 3.1.1 by xtable 1.7-3 package -->
<!-- Tue Aug 12 18:26:55 2014 -->
<TABLE border=1>
<TR> <TH>  </TH> <TH> 
RandomForest
</TH> <TH> 
GBM
</TH> <TH> 
LDA
</TH> <TH> 
RandomForest-PCA
</TH>  </TR>
  <TR> <TD align="right"> 
Accuracy
</TD> <TD align="right"> 
0.99
</TD> <TD align="right"> 
0.96
</TD> <TD align="right"> 
0.70
</TD> <TD align="right"> 
0.98
</TD> </TR>
  <TR> <TD align="right"> 
Elapsed Time
</TD> <TD align="right"> 
1847.07
</TD> <TD align="right"> 
723.55
</TD> <TD align="right"> 
4.43
</TD> <TD align="right"> 
1628.12
</TD> </TR>
   </TABLE>

<p></BR></p>
<p>From the table above, we see that using PCA to reduce the rank of the training set does not give significantly less processing time. Hence considering the amount of time used and the accuracy, we would use the Random Forest model as or final model. </BR> </BR></p>
</div>
<div id="exploratory-analysis" class="section level2">
<h2>Exploratory Analysis</h2>
<p>In this section, it would be interesting to explore the relationships among the top 5 most important variables used for modelling (Random Forest).</p>
<pre class="r"><code>x &lt;- varImp(modFit.rf)$importance
x &lt;- row.names(x)
x &lt;- x[1:5]
train.sub &lt;- subset(train, select=c(x,&quot;classe&quot;))
train.sub$classe &lt;- factor(train.sub$classe)

featurePlot(x=train.sub[,-6], y=train.sub[,6],plot=&quot;pairs&quot;, auto.key=list(columns=5))</code></pre>
<p><img src="Project_files/figure-html/importantvariable.png" title="plot of chunk importantvariable" alt="plot of chunk importantvariable" width="853.44" /></p>
<p>From the plot above, we see that “roll_belt” variable gives very distinct clustering of the data. This might suggest that it helps captures most of the key features in the dataset. As compared to “gyros_belt_x”, which has a larger tendency to form featureless plots.</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with --self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
